# cP-library counts preparation

# generate files with raw counts for positive and negative strands separately from the alignment:
# final raw count file includes positions for individual transcripts

# this is a sub-pipeline!

import os

workdir: config['output']

output_dir = config['output']

samples, = glob_wildcards(os.path.join(output_dir, "{samples}-cP" + ".sorted.dedup.bam"))


# keep only hits of read2 of properly mapped pairs (147/163) AND only unique hits
rule filter_unique_mapped_reads_cP:
    input:
        bams = os.path.join(output_dir, "{index}-cP" +
                                                  ".sorted.dedup.bam")
    output:
        unique_reads = temp(os.path.join(output_dir, "{index}-cP" +
                                                  ".sorted.dedup.unique.bam"))
    shell:
        """(samtools view -H {input.bams}; samtools view -f 0x2 -f 0x80 -F 0x100 {input.bams} | grep -E "\<NH:i:1\>") | samtools view -b > {output.unique_reads}"""


# collect alignment stats after filtering
rule collect_alignment_stats_after_filtering_cP:
    input:
        unique_reads = rules.filter_unique_mapped_reads_cP.output.unique_reads
    output:
        logs = os.path.join(output_dir,"{index}-cP" +
                                                  ".sorted.dedup.unique.stats")
    shell:
        """samtools stats {input.unique_reads} | grep ^SN | cut -f 2- > {output.logs}"""


# convert bam to bed
rule convert_bam_to_bed_cP:
    input:
        bam = rules.filter_unique_mapped_reads_cP.output.unique_reads
    output:
        bed = temp(os.path.join(output_dir,"{index}-cP" +
                                                      ".sorted.dedup.unique.bed"))
    shell:
        """bedtools bamtobed -i {input.bam} > {output.bed}"""


# intersections with transcriptome
rule intersect_alignment_with_transcriptome_cP:
    input:
        bed = rules.convert_bam_to_bed_cP.output.bed,
        no_overlaps = os.path.join(output_dir, 'transcripts.no_overlaps.gff')
    output:
        filtered_bed = os.path.join(output_dir,"{index}-cP" +
                                                      ".sorted.dedup.unique.intersect.bed")
    shell:
        """bedtools intersect -u -S -f 1.0 -a {input.bed} -b {input.no_overlaps} > {output.filtered_bed}"""


# coverage of transcriptome (per transcript in gff)
rule find_transcripts_coverage_cP:
    input:
        filtered_bed = rules.intersect_alignment_with_transcriptome_cP.output.filtered_bed,
        no_overlaps = os.path.join(output_dir, 'transcripts.no_overlaps.gff')
    output:
        transcripts_coverage = temp(os.path.join(output_dir, "{index}-cP" +
                                                  ".transcripts.coverage.gff"))
    run:
        shell("""bedtools coverage -S -a {input.no_overlaps} -b {input.filtered_bed} > {output.transcripts_coverage}""")


# on + strand count STARTS (corresponds to signal of opposite strand)
rule collect_raw_counts_cP_minus:
    input:
        filtered_bed = rules.intersect_alignment_with_transcriptome_cP.output.filtered_bed
    params:
        awk_strand = '$6=="+"'
    output:
        p_minus_strand = os.path.join(output_dir,"{index}-cP" +
                                                      ".sorted.dedup.unique.intersect.neg_strand.raw_count")
    shell:
        """awk '{params.awk_strand}' {input.filtered_bed} |  sort -t$'\\t' -k1,1 -k2,2n | awk -F '\\t' '{{print $1,$2}}' |  uniq -c > {output.p_minus_strand}"""


# on - strand count ENDS (corresponds to signal of opposite strand), BED coordinates are semi-open => end-1!
rule collect_raw_counts_cP_plus:
    input:
        filtered_bed = rules.intersect_alignment_with_transcriptome_cP.output.filtered_bed
    params:
        awk_strand ='$6=="-"'
    output:
        cP_plus_strand = os.path.join(output_dir,"{index}-cP" +
                                                      ".sorted.dedup.unique.intersect.pos_strand.raw_count")
    shell:
        """awk '{params.awk_strand}' {input.filtered_bed} |  sort -t$'\\t' -k1,1 -k3,3n | awk -F '\\t' '{{print $1,$3-1}}' |  uniq -c > {output.cP_plus_strand}"""
